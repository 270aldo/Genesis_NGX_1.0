name: Quality Gates and Code Standards

on:
  pull_request:
    branches: [ main, develop ]
  push:
    branches: [ main, develop ]

env:
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.11'

jobs:
  # Quality Gate 1: Code Standards and Linting
  code-standards:
    name: Code Standards
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for better analysis

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Install Poetry
      uses: snok/install-poetry@v1

    - name: Install backend dependencies
      run: |
        cd backend
        poetry install --with dev

    - name: Install frontend dependencies
      run: |
        cd frontend
        npm ci

    - name: Backend linting (Ruff)
      run: |
        cd backend
        poetry run ruff check . --output-format=github

    - name: Backend type checking (MyPy)
      run: |
        cd backend
        poetry run mypy . --ignore-missing-imports

    - name: Backend code formatting check (Black)
      run: |
        cd backend
        poetry run black --check --diff .

    - name: Backend import sorting check (isort)
      run: |
        cd backend
        poetry run isort --check-only --diff .

    - name: Frontend linting (ESLint)
      run: |
        cd frontend
        npm run lint

    - name: Frontend type checking (TypeScript)
      run: |
        cd frontend
        npm run type-check || npx tsc --noEmit

    - name: Frontend code formatting check (Prettier)
      run: |
        cd frontend
        npx prettier --check "src/**/*.{ts,tsx,js,jsx,json,css,md}"

    - name: Check for TODO/FIXME comments
      run: |
        echo "Checking for TODO/FIXME comments..."
        TODO_COUNT=$(grep -r "TODO\|FIXME" --include="*.py" --include="*.ts" --include="*.tsx" --include="*.js" backend/ frontend/ | wc -l)
        echo "Found $TODO_COUNT TODO/FIXME comments"
        if [ $TODO_COUNT -gt 50 ]; then
          echo "❌ Too many TODO/FIXME comments ($TODO_COUNT). Please address some before merging."
          exit 1
        fi

  # Quality Gate 2: Security Scan
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Run Bandit security scan (Python)
      run: |
        pip install bandit
        bandit -r backend/ -f json -o bandit-report.json || true
        bandit -r backend/ -ll  # Only high and medium severity

    - name: Run npm audit (Node.js)
      run: |
        cd frontend
        npm audit --audit-level high

    - name: Check for hardcoded secrets
      uses: trufflesecurity/trufflehog@main
      with:
        path: ./
        base: main
        head: HEAD
        extra_args: --debug --only-verified

    - name: Upload security scan results
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: security-scan-results
        path: |
          bandit-report.json
        retention-days: 7

  # Quality Gate 3: Test Coverage Requirements
  coverage-requirements:
    name: Coverage Requirements
    runs-on: ubuntu-latest

    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: genesis_test
        ports:
          - 5432:5432

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Install backend dependencies
      run: |
        cd backend
        pip install poetry
        poetry install --with dev,test

    - name: Install frontend dependencies
      run: |
        cd frontend
        npm ci

    - name: Set up test environment
      run: |
        cd backend
        cp .env.example .env.test
        echo "REDIS_URL=redis://localhost:6379/1" >> .env.test
        echo "DATABASE_URL=postgresql://postgres:postgres@localhost:5432/genesis_test" >> .env.test

    - name: Run backend tests with coverage
      run: |
        cd backend
        poetry run pytest --cov=core --cov=agents --cov=clients --cov=app \
          --cov-report=xml --cov-report=term-missing \
          --cov-fail-under=85 \
          tests/unit/ tests/integration/

    - name: Run frontend tests with coverage
      run: |
        cd frontend
        npm run test:coverage -- --coverage --watchAll=false --passWithNoTests

    - name: Check backend coverage threshold
      run: |
        cd backend
        poetry run coverage report --fail-under=85

    - name: Check frontend coverage threshold
      run: |
        cd frontend
        node -e "
        const coverage = require('./coverage/coverage-summary.json');
        const totalCoverage = coverage.total.lines.pct;
        console.log(\`Frontend coverage: \${totalCoverage}%\`);
        if (totalCoverage < 80) {
          console.error('❌ Frontend coverage below 80% threshold');
          process.exit(1);
        }
        console.log('✅ Frontend coverage meets threshold');
        "

    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: |
          backend/coverage.xml
          frontend/coverage/lcov.info
        fail_ci_if_error: false

  # Quality Gate 4: API Contract Validation
  api-contract-validation:
    name: API Contract Validation
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python and start backend
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Start backend for contract testing
      run: |
        cd backend
        pip install poetry
        poetry install --only main
        poetry run uvicorn app.main:app --host 0.0.0.0 --port 8000 &
        sleep 30

    - name: Validate OpenAPI schema
      run: |
        # Check if OpenAPI schema is accessible
        curl -f http://localhost:8000/openapi.json > openapi.json

        # Validate schema structure
        node -e "
        const schema = require('./openapi.json');
        console.log('API Title:', schema.info.title);
        console.log('API Version:', schema.info.version);
        console.log('Endpoints:', Object.keys(schema.paths).length);

        // Basic validation
        if (!schema.info.title || !schema.info.version || !schema.paths) {
          console.error('❌ Invalid OpenAPI schema structure');
          process.exit(1);
        }
        console.log('✅ OpenAPI schema structure valid');
        "

    - name: Run contract tests
      run: |
        cd backend
        poetry run pytest tests/contract/ -v --maxfail=10

    - name: Validate API backwards compatibility
      if: github.event_name == 'pull_request'
      run: |
        # In a real scenario, this would compare against the main branch API schema
        echo "Validating API backwards compatibility..."
        echo "✅ No breaking changes detected (placeholder)"

  # Quality Gate 5: Performance Benchmarks
  performance-benchmarks:
    name: Performance Benchmarks
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up services for performance testing
      run: |
        cd backend
        pip install poetry
        poetry install --only main
        poetry run uvicorn app.main:app --host 0.0.0.0 --port 8000 &
        sleep 30

    - name: Install K6
      uses: grafana/setup-k6-action@v1

    - name: Run performance benchmarks
      run: |
        cd load-tests
        k6 run --duration 2m --vus 5 tests/smoke-test.js || k6 run tests/load-test.js
      env:
        ENVIRONMENT: local

    - name: Validate performance thresholds
      run: |
        echo "Performance validation complete"
        # Add logic to parse K6 results and validate thresholds

  # Quality Gate 6: AI Response Quality
  ai-response-quality:
    name: AI Response Quality
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        cd backend
        pip install poetry
        poetry install --with dev,test

    - name: Run AI semantic quality tests
      run: |
        cd backend
        poetry run pytest tests/ai/ -v --maxfail=5

    - name: Validate AI agent response quality
      run: |
        cd backend
        poetry run python -c "
        from tests.ai.semantic_validator import SemanticValidator
        import asyncio

        async def validate_quality():
            validator = SemanticValidator()

            # Test sample responses for quality
            test_cases = [
                ('I want to build muscle', 'Start with compound exercises like squats and deadlifts...', 'BLAZE'),
                ('I need a meal plan', 'Focus on balanced macros with adequate protein...', 'SAGE'),
                ('Show my progress', 'Your strength has improved by 15% this month...', 'STELLA')
            ]

            results = []
            for query, response, agent in test_cases:
                result = await validator.validate_response(query, response, agent)
                results.append(result)

            avg_quality = sum(r.overall_score for r in results) / len(results)
            print(f'Average AI response quality: {avg_quality:.2f}')

            if avg_quality < 0.8:
                print('❌ AI response quality below threshold')
                return False
            else:
                print('✅ AI response quality meets standards')
                return True

        success = asyncio.run(validate_quality())
        exit(0 if success else 1)
        "

  # Quality Gate 7: Dependency Security
  dependency-security:
    name: Dependency Security
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Run Safety check (Python)
      run: |
        pip install safety
        safety check --json --output safety-report.json || true
        safety check --short-report

    - name: Check Python dependencies for known vulnerabilities
      run: |
        pip install pip-audit
        pip-audit --desc --format=json --output=pip-audit-report.json || true
        pip-audit --desc

    - name: Run npm audit (Node.js)
      run: |
        cd frontend
        npm audit --json > npm-audit-report.json || true
        npm audit

    - name: Upload dependency security reports
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: dependency-security-reports
        path: |
          safety-report.json
          pip-audit-report.json
          frontend/npm-audit-report.json
        retention-days: 7

  # Quality Gate Summary
  quality-gate-summary:
    name: Quality Gate Summary
    runs-on: ubuntu-latest
    needs: [
      code-standards,
      security-scan,
      coverage-requirements,
      api-contract-validation,
      performance-benchmarks,
      ai-response-quality,
      dependency-security
    ]
    if: always()

    steps:
    - name: Check quality gate results
      run: |
        echo "Quality Gate Results:"
        echo "Code Standards: ${{ needs.code-standards.result }}"
        echo "Security Scan: ${{ needs.security-scan.result }}"
        echo "Coverage Requirements: ${{ needs.coverage-requirements.result }}"
        echo "API Contract Validation: ${{ needs.api-contract-validation.result }}"
        echo "Performance Benchmarks: ${{ needs.performance-benchmarks.result }}"
        echo "AI Response Quality: ${{ needs.ai-response-quality.result }}"
        echo "Dependency Security: ${{ needs.dependency-security.result }}"

        # Check if any quality gate failed
        if [[ "${{ needs.code-standards.result }}" == "failure" ]] || \
           [[ "${{ needs.security-scan.result }}" == "failure" ]] || \
           [[ "${{ needs.coverage-requirements.result }}" == "failure" ]] || \
           [[ "${{ needs.api-contract-validation.result }}" == "failure" ]] || \
           [[ "${{ needs.ai-response-quality.result }}" == "failure" ]]; then
          echo "❌ One or more quality gates failed"
          exit 1
        else
          echo "✅ All quality gates passed"
        fi

    - name: Update pull request status
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const allPassed = [
            '${{ needs.code-standards.result }}',
            '${{ needs.security-scan.result }}',
            '${{ needs.coverage-requirements.result }}',
            '${{ needs.api-contract-validation.result }}',
            '${{ needs.performance-benchmarks.result }}',
            '${{ needs.ai-response-quality.result }}',
            '${{ needs.dependency-security.result }}'
          ].every(result => result === 'success');

          const statusEmoji = allPassed ? '✅' : '❌';
          const statusText = allPassed ? 'All quality gates passed' : 'Some quality gates failed';

          const body = `
          ## ${statusEmoji} Quality Gate Summary

          ${statusText}

          ### Results:
          - **Code Standards**: ${{ needs.code-standards.result }}
          - **Security Scan**: ${{ needs.security-scan.result }}
          - **Coverage Requirements**: ${{ needs.coverage-requirements.result }}
          - **API Contract Validation**: ${{ needs.api-contract-validation.result }}
          - **Performance Benchmarks**: ${{ needs.performance-benchmarks.result }}
          - **AI Response Quality**: ${{ needs.ai-response-quality.result }}
          - **Dependency Security**: ${{ needs.dependency-security.result }}

          ${allPassed ?
            '🚀 This pull request meets all quality standards and is ready for review!' :
            '⚠️ Please address the failing quality gates before merging.'
          }
          `;

          // Find existing quality gate comment
          const { data: comments } = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
          });

          const existingComment = comments.find(comment =>
            comment.body.includes('Quality Gate Summary')
          );

          if (existingComment) {
            // Update existing comment
            await github.rest.issues.updateComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: existingComment.id,
              body: body
            });
          } else {
            // Create new comment
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: body
            });
          }
