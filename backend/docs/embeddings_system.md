# ğŸ¦¾ Sistema de Embeddings - NGX Agents

## DescripciÃ³n General

El sistema de embeddings de NGX Agents proporciona una infraestructura completa para generar, almacenar y buscar embeddings vectoriales de alta dimensiÃ³n. Utiliza el modelo mÃ¡s avanzado de Google (`text-embedding-large-exp-03-07`) y combina almacenamiento persistente en la nube con bÃºsqueda vectorial escalable.

## Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AplicaciÃ³n NGX                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   EmbeddingsManager                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ GeneraciÃ³n   â”‚ Almacenamientoâ”‚      BÃºsqueda          â”‚ â”‚
â”‚  â”‚ Embeddings   â”‚   HÃ­brido     â”‚   Inteligente          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚               â”‚                  â”‚                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         â–¼               â–¼                  â–¼                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Vertex AI   â”‚ â”‚    GCS      â”‚ â”‚ Vector Search  â”‚        â”‚
â”‚  â”‚ Embeddings  â”‚ â”‚  Storage    â”‚ â”‚   (Vertex AI)  â”‚        â”‚
â”‚  â”‚ API Model   â”‚ â”‚  (Bucket)   â”‚ â”‚ Index+Endpoint â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚         â”‚               â”‚                  â”‚                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              CachÃ© en Memoria (Redis/Local)            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Componentes Principales

### 1. EmbeddingsManager (`core/embeddings_manager.py`)

Gestor centralizado que coordina todas las operaciones de embeddings.

**CaracterÃ­sticas principales:**
- GeneraciÃ³n de embeddings individuales y en lote
- Almacenamiento hÃ­brido (memoria + GCS)
- BÃºsqueda semÃ¡ntica con fallback inteligente
- GestiÃ³n de cachÃ© con TTL configurable
- EstadÃ­sticas y mÃ©tricas de uso

**ConfiguraciÃ³n:**
```python
embeddings_manager = EmbeddingsManager(
    cache_enabled=True,
    cache_ttl=86400,  # 24 horas
    vector_dimension=3072,  # Para text-embedding-large-exp-03-07
    similarity_threshold=0.7,
    use_gcs=True,
    gcs_prefix="embeddings/",
    use_vector_search=True
)
```

### 2. Modelo de Embeddings

**Modelo**: `text-embedding-large-exp-03-07`
- **Dimensiones**: 3072
- **Tipo**: Experimental de Google (mejor rendimiento)
- **Ventajas**: Mayor precisiÃ³n en bÃºsquedas semÃ¡nticas
- **Casos de uso**: Contexto de conversaciones, bÃºsqueda de conocimiento

### 3. Almacenamiento en GCS

**ConfiguraciÃ³n:**
- **Bucket**: `agents_ngx`
- **RegiÃ³n**: US (multi-regiÃ³n)
- **Estructura**: `embeddings/{key}.json`
- **Formato**: JSON con embedding, texto, metadata y timestamp

**Ventajas:**
- Almacenamiento ilimitado y econÃ³mico
- Backup automÃ¡tico
- Acceso global
- IntegraciÃ³n nativa con Google Cloud

### 4. Vector Search

**ConfiguraciÃ³n:**
- **Index ID**: `5755708075919015936`
- **Endpoint ID**: `9027115808366526464`
- **Algoritmo**: Tree-AH (optimizado para alta precisiÃ³n)
- **Neighbors**: 100 (bÃºsquedas amplias)
- **Distancia**: Coseno (ideal para embeddings normalizados)

**CaracterÃ­sticas:**
- BÃºsqueda en millones de vectores en milisegundos
- Escalabilidad automÃ¡tica
- Filtros avanzados
- ActualizaciÃ³n en lote

## API de Uso

### Generar Embeddings

```python
# Individual
embedding = await embeddings_manager.generate_embedding("Texto a convertir")

# En lote
embeddings = await embeddings_manager.batch_generate_embeddings([
    "Texto 1",
    "Texto 2",
    "Texto 3"
])
```

### Almacenar Embeddings

```python
# Almacenar con metadata
success = await embeddings_manager.store_embedding(
    key="conversation_123",
    text="Â¿CuÃ¡l es el mejor ejercicio para ganar mÃºsculo?",
    metadata={
        "user_id": "user_456",
        "agent": "training_strategist",
        "timestamp": "2025-05-31T20:00:00Z"
    }
)

# Almacenamiento en lote
items = [
    {
        "key": "doc_001",
        "text": "Plan de entrenamiento de fuerza",
        "metadata": {"type": "training_plan"}
    },
    {
        "key": "doc_002",
        "text": "GuÃ­a nutricional para volumen",
        "metadata": {"type": "nutrition_guide"}
    }
]
results = await embeddings_manager.batch_store_embeddings(items)
```

### Buscar por Similitud

```python
# BÃºsqueda semÃ¡ntica
results = await embeddings_manager.find_similar(
    query="ejercicios para brazos",
    top_k=5,
    threshold=0.7
)

# Procesar resultados
for result in results:
    print(f"Key: {result['key']}")
    print(f"Texto: {result['text']}")
    print(f"Similitud: {result['similarity']:.3f}")
    print(f"Metadata: {result['metadata']}")
```

### GestiÃ³n de Embeddings

```python
# Obtener por clave
item = await embeddings_manager.get_by_key("conversation_123")

# Eliminar
deleted = await embeddings_manager.delete_by_key("conversation_123")

# EstadÃ­sticas
stats = await embeddings_manager.get_stats()
print(f"Embeddings en memoria: {stats['store_size']}")
print(f"Embeddings en GCS: {stats['gcs_embeddings_count']}")
print(f"BÃºsquedas realizadas: {stats['stats']['similarity_searches']}")
```

## Flujo de BÃºsqueda

1. **Query** â†’ Generar embedding del texto de bÃºsqueda
2. **Vector Search** â†’ Buscar en Ã­ndice escalable (si disponible)
3. **Fallback Local** â†’ Buscar en memoria si Vector Search falla
4. **GCS Sync** â†’ Cargar embeddings desde GCS si necesario
5. **Resultados** â†’ Retornar items ordenados por similitud

## Optimizaciones Implementadas

### 1. CachÃ© Multinivel
- **L1**: CachÃ© de texto a embedding (evita regenerar)
- **L2**: Embeddings en memoria (acceso rÃ¡pido)
- **L3**: GCS para persistencia
- **L4**: Vector Search para escala

### 2. Procesamiento Eficiente
- GeneraciÃ³n en lote para mÃºltiples textos
- ParalelizaciÃ³n de operaciones I/O
- LÃ­mites de cachÃ© inteligentes
- Limpieza automÃ¡tica de cachÃ© antiguo

### 3. Resiliencia
- Fallback automÃ¡tico entre niveles
- Reintentos con backoff exponencial
- Logging detallado de errores
- MÃ©tricas de rendimiento

## Casos de Uso en NGX Agents

### 1. Contexto de ConversaciÃ³n
```python
# Almacenar cada intercambio
await embeddings_manager.store_embedding(
    key=f"conv_{session_id}_{timestamp}",
    text=f"{user_message} {agent_response}",
    metadata={
        "session_id": session_id,
        "user_id": user_id,
        "agent": agent_name
    }
)

# Buscar contexto relevante
context = await embeddings_manager.find_similar(
    query=current_message,
    top_k=10
)
```

### 2. Base de Conocimiento
```python
# Indexar documentos
for doc in training_documents:
    await embeddings_manager.store_embedding(
        key=f"kb_{doc.id}",
        text=doc.content,
        metadata={
            "category": doc.category,
            "tags": doc.tags
        }
    )

# Buscar informaciÃ³n relevante
relevant_docs = await embeddings_manager.find_similar(
    query="tÃ©cnicas de recuperaciÃ³n muscular",
    top_k=5,
    threshold=0.8
)
```

### 3. PersonalizaciÃ³n de Usuario
```python
# Almacenar preferencias
await embeddings_manager.store_embedding(
    key=f"user_pref_{user_id}",
    text=" ".join(user_preferences),
    metadata={"user_id": user_id}
)

# Encontrar usuarios similares
similar_users = await embeddings_manager.find_similar(
    query=current_user_profile,
    top_k=20
)
```

## ConfiguraciÃ³n y Deployment

### Variables de Entorno

```env
# Google Cloud
GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json
GCP_PROJECT_ID=agentes-ngx
VERTEX_LOCATION=us-central1

# GCS
GCS_BUCKET_NAME=agents_ngx
GCS_BUCKET_LOCATION=us

# Vector Search
VERTEX_AI_INDEX_ID=5755708075919015936
VERTEX_AI_INDEX_ENDPOINT_ID=9027115808366526464

# CachÃ©
USE_REDIS_CACHE=true
REDIS_HOST=localhost
REDIS_PORT=6379
```

### InicializaciÃ³n

```python
# En app/main.py o donde se inicialice
from core.embeddings_manager import embeddings_manager

# El manager se auto-inicializa cuando se usa
# Opcionalmente, pre-cargar embeddings
await embeddings_manager._load_embeddings_from_gcs(limit=1000)
```

### Scripts de Utilidad

```bash
# Probar el sistema completo
python scripts/test_embeddings_integration.py

# Migrar embeddings existentes
python scripts/migrate_embeddings_to_gcs.py

# Reindexar en Vector Search
python scripts/reindex_vector_search.py
```

## Monitoreo y MÃ©tricas

### MÃ©tricas Disponibles

1. **Rendimiento**:
   - Tiempo de generaciÃ³n de embeddings
   - Latencia de bÃºsqueda
   - Hit rate del cachÃ©

2. **Uso**:
   - Total de embeddings almacenados
   - BÃºsquedas por minuto
   - TamaÃ±o del cachÃ©

3. **Errores**:
   - Fallos de generaciÃ³n
   - Timeouts de Vector Search
   - Errores de GCS

### Dashboard Recomendado

```python
# Obtener mÃ©tricas
stats = await embeddings_manager.get_stats()

# MÃ©tricas clave
print(f"Cache hit rate: {stats['stats']['cache_hits'] / stats['stats']['embedding_requests']:.2%}")
print(f"BÃºsquedas/hora: {stats['stats']['similarity_searches'] * 60}")
print(f"Errores: {stats['stats']['errors']}")
```

## Mejores PrÃ¡cticas

### 1. Claves Ãšnicas
- Usar UUIDs o hashes para evitar colisiones
- Incluir tipo de contenido en la clave
- Ejemplo: `conv_{uuid}`, `kb_doc_{id}`, `user_pref_{user_id}`

### 2. Metadata Rica
- Incluir toda informaciÃ³n relevante para filtrado
- Timestamps para ordenamiento temporal
- CategorÃ­as para agrupaciÃ³n

### 3. Limpieza Regular
- Eliminar embeddings antiguos no usados
- Implementar TTL para contenido temporal
- Monitorear crecimiento del storage

### 4. BÃºsquedas Eficientes
- Usar threshold apropiado (0.7-0.8 tÃ­picamente)
- Limitar top_k segÃºn necesidad
- Pre-filtrar cuando sea posible

## Troubleshooting

### Problema: Embeddings no se generan
**SoluciÃ³n**: Verificar credenciales de Google Cloud y cuota de API

### Problema: Vector Search no retorna resultados
**SoluciÃ³n**: Verificar que el Ã­ndice estÃ© desplegado y el endpoint activo

### Problema: Alta latencia en bÃºsquedas
**SoluciÃ³n**: Aumentar cachÃ© en memoria, optimizar threshold

### Problema: Costos elevados de GCS
**SoluciÃ³n**: Implementar lifecycle policies, comprimir embeddings

## Roadmap Futuro

1. **CompresiÃ³n de Embeddings**: Reducir tamaÃ±o sin perder precisiÃ³n
2. **Multi-tenancy**: SeparaciÃ³n por organizaciÃ³n
3. **Embeddings Multimodales**: Soporte para imÃ¡genes y audio
4. **Fine-tuning**: Modelos especializados por dominio
5. **Analytics Avanzado**: Clustering y visualizaciÃ³n de embeddings

---

Esta documentaciÃ³n cubre la implementaciÃ³n completa del sistema de embeddings en NGX Agents. Para preguntas especÃ­ficas o casos de uso adicionales, consultar el cÃ³digo fuente o contactar al equipo de desarrollo.