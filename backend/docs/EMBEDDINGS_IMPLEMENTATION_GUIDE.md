# ğŸ§  GuÃ­a de ImplementaciÃ³n del Sistema de Embeddings

## ğŸ“‹ Resumen del Sistema

El sistema de embeddings de GENESIS NGX utiliza tecnologÃ­a de Google Vertex AI para convertir texto en representaciones vectoriales de alta dimensiÃ³n, permitiendo bÃºsquedas semÃ¡nticas avanzadas y recuperaciÃ³n de contexto inteligente.

### CaracterÃ­sticas Principales:
- **Modelo**: `text-embedding-large-exp-03-07` (3072 dimensiones)
- **Almacenamiento HÃ­brido**: Memoria + GCS + Vector Search
- **CachÃ© Multinivel**: L1 (textoâ†’embedding), L2 (memoria), L3 (GCS), L4 (Vector Search)
- **BÃºsqueda SemÃ¡ntica**: Similitud coseno con threshold configurable

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AplicaciÃ³n NGX                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   EmbeddingsManager                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ GeneraciÃ³n   â”‚ Almacenamientoâ”‚      BÃºsqueda          â”‚ â”‚
â”‚  â”‚ Embeddings   â”‚   HÃ­brido     â”‚   Inteligente          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚               â”‚                  â”‚                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         â–¼               â–¼                  â–¼                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Vertex AI   â”‚ â”‚    GCS      â”‚ â”‚ Vector Search  â”‚        â”‚
â”‚  â”‚ Embeddings  â”‚ â”‚  Storage    â”‚ â”‚   (Vertex AI)  â”‚        â”‚
â”‚  â”‚ API Model   â”‚ â”‚  (Bucket)   â”‚ â”‚ Index+Endpoint â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Uso del Sistema

### 1. Generar Embeddings

```python
from core.embeddings_manager import embeddings_manager

# Individual
embedding = await embeddings_manager.generate_embedding("Texto a convertir")

# En lote (mÃ¡s eficiente)
embeddings = await embeddings_manager.batch_generate_embeddings([
    "Texto 1",
    "Texto 2",
    "Texto 3"
])
```

### 2. Almacenar con Metadata

```python
# Almacenar contexto de conversaciÃ³n
success = await embeddings_manager.store_embedding(
    key="conversation_123",
    text="Â¿CuÃ¡l es el mejor ejercicio para ganar mÃºsculo?",
    metadata={
        "user_id": "user_456",
        "agent": "training_strategist",
        "timestamp": "2025-07-19T20:00:00Z"
    }
)
```

### 3. Buscar por Similitud

```python
# Buscar contexto relevante
results = await embeddings_manager.find_similar(
    query="ejercicios para brazos",
    top_k=5,
    threshold=0.7
)

for result in results:
    print(f"Texto: {result['text']}")
    print(f"Similitud: {result['similarity']:.3f}")
    print(f"Metadata: {result['metadata']}")
```

## ğŸ’¡ Casos de Uso en GENESIS

### 1. Contexto de ConversaciÃ³n
Cada intercambio usuario-agente se almacena como embedding para mantener contexto a largo plazo:

```python
# En el orchestrator
await embeddings_manager.store_embedding(
    key=f"conv_{session_id}_{timestamp}",
    text=f"{user_message} {agent_response}",
    metadata={
        "session_id": session_id,
        "user_id": user_id,
        "agent": agent_name,
        "intent": primary_intent
    }
)
```

### 2. Base de Conocimiento
Los documentos de entrenamiento y nutriciÃ³n se indexan para bÃºsqueda rÃ¡pida:

```python
# Indexar documentos
for doc in training_documents:
    await embeddings_manager.store_embedding(
        key=f"kb_{doc.id}",
        text=doc.content,
        metadata={
            "category": doc.category,
            "tags": doc.tags,
            "source": "knowledge_base"
        }
    )
```

### 3. PersonalizaciÃ³n de Usuario
Las preferencias y objetivos del usuario se convierten en embeddings para encontrar patrones similares:

```python
# Almacenar perfil de usuario
user_profile = f"""
Objetivos: {user.goals}
Nivel: {user.fitness_level}
Preferencias: {user.preferences}
"""

await embeddings_manager.store_embedding(
    key=f"user_profile_{user_id}",
    text=user_profile,
    metadata={"user_id": user_id, "type": "profile"}
)
```

## âš™ï¸ ConfiguraciÃ³n

### Variables de Entorno

```env
# Google Cloud
GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json
GCP_PROJECT_ID=agentes-ngx
VERTEX_LOCATION=us-central1

# GCS
GCS_BUCKET_NAME=agents_ngx

# Vector Search (IDs del Ã­ndice y endpoint)
VERTEX_AI_INDEX_ID=5755708075919015936
VERTEX_AI_INDEX_ENDPOINT_ID=9027115808366526464

# CachÃ©
USE_REDIS_CACHE=true
REDIS_URL=redis://localhost:6379
```

### VerificaciÃ³n de ConfiguraciÃ³n

```bash
# Verificar que Vector Search estÃ© configurado
python scripts/verify_vector_search.py

# Probar el sistema de embeddings
python scripts/test_embeddings_integration.py
```

## ğŸ” Flujo de BÃºsqueda

1. **Query** â†’ Se genera embedding del texto de bÃºsqueda
2. **Vector Search** â†’ BÃºsqueda en Ã­ndice escalable (si estÃ¡ configurado)
3. **Fallback Local** â†’ BÃºsqueda en memoria si Vector Search falla
4. **GCS Sync** â†’ Carga embeddings desde GCS si es necesario
5. **Resultados** â†’ Retorna items ordenados por similitud

## ğŸ“Š Monitoreo y MÃ©tricas

```python
# Obtener estadÃ­sticas del sistema
stats = await embeddings_manager.get_stats()

print(f"Embeddings en memoria: {stats['store_size']}")
print(f"Embeddings en GCS: {stats['gcs_embeddings_count']}")
print(f"BÃºsquedas realizadas: {stats['stats']['similarity_searches']}")
print(f"Cache hit rate: {stats['stats']['cache_hits'] / stats['stats']['embedding_requests']:.2%}")
```

## ğŸš¨ Consideraciones Importantes

### 1. Costos
- Cada embedding generation tiene un costo en Vertex AI
- Usar cachÃ© agresivamente para reducir costos
- Batch operations son mÃ¡s eficientes que individuales

### 2. Rendimiento
- Los embeddings son de 3072 dimensiones (12KB por embedding)
- Limitar embeddings en memoria segÃºn recursos disponibles
- Vector Search es necesario para escalar a millones de embeddings

### 3. Seguridad
- No almacenar informaciÃ³n sensible en embeddings
- Los embeddings pueden ser parcialmente reversibles
- Aplicar sanitizaciÃ³n antes de generar embeddings

## ğŸ› ï¸ Troubleshooting

### Problema: Vector Search no retorna resultados
**SoluciÃ³n**: 
1. Verificar que el Ã­ndice tenga datos: `scripts/verify_vector_search.py`
2. Verificar que el endpoint estÃ© desplegado
3. Revisar logs en GCP Console

### Problema: Alta latencia en bÃºsquedas
**SoluciÃ³n**:
1. Aumentar cachÃ© en memoria
2. Ajustar threshold de similitud (mÃ¡s alto = menos resultados)
3. Usar Vector Search en lugar de bÃºsqueda local

### Problema: Embeddings no se generan
**SoluciÃ³n**:
1. Verificar credenciales de Google Cloud
2. Verificar cuota de API en Vertex AI
3. Revisar logs: `grep "embedding" logs/app.log`

## ğŸ“š Referencias

- [Vertex AI Embeddings](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings)
- [Vector Search](https://cloud.google.com/vertex-ai/docs/vector-search/overview)
- [Similitud Coseno](https://en.wikipedia.org/wiki/Cosine_similarity)

---

**Ãšltima actualizaciÃ³n**: 2025-07-19