#!/usr/bin/env python3
"""
Script para analizar el rendimiento de las queries en Supabase.

Este script se conecta a la base de datos y analiza:
- Queries m√°s lentas
- √çndices no utilizados
- Sugerencias de nuevos √≠ndices
- Estad√≠sticas de tablas
"""

import asyncio
import os
from datetime import datetime, timedelta
from typing import List, Dict, Any
import asyncpg
from tabulate import tabulate

from core.logging_config import get_logger
from config.secrets import settings

logger = get_logger(__name__)


async def get_database_connection():
    """Obtiene una conexi√≥n directa a la base de datos."""
    # Construir URL de conexi√≥n desde Supabase
    db_url = settings.SUPABASE_URL.replace('https://', '')
    db_url = db_url.split('.')[0]  # Obtener el ID del proyecto
    
    # La URL de conexi√≥n directa de Supabase sigue este patr√≥n
    connection_url = f"postgresql://postgres:{settings.SUPABASE_SERVICE_ROLE_KEY}@db.{db_url}.supabase.co:5432/postgres"
    
    return await asyncpg.connect(connection_url)


async def analyze_slow_queries(conn: asyncpg.Connection, limit: int = 10):
    """Analiza las queries m√°s lentas."""
    print("\n=== QUERIES M√ÅS LENTAS ===\n")
    
    query = """
    SELECT 
        query,
        calls,
        total_time,
        mean_time,
        min_time,
        max_time
    FROM pg_stat_statements
    WHERE query NOT LIKE '%pg_%'
    ORDER BY mean_time DESC
    LIMIT $1;
    """
    
    try:
        rows = await conn.fetch(query, limit)
        
        if rows:
            headers = ["Query", "Llamadas", "Tiempo Total (ms)", "Tiempo Promedio (ms)", "Min (ms)", "Max (ms)"]
            data = []
            
            for row in rows:
                data.append([
                    row['query'][:50] + "..." if len(row['query']) > 50 else row['query'],
                    row['calls'],
                    f"{row['total_time']:.2f}",
                    f"{row['mean_time']:.2f}",
                    f"{row['min_time']:.2f}",
                    f"{row['max_time']:.2f}"
                ])
            
            print(tabulate(data, headers=headers, tablefmt="grid"))
        else:
            print("No se encontraron estad√≠sticas de queries.")
            print("Nota: pg_stat_statements debe estar habilitado en Supabase.")
    
    except Exception as e:
        logger.warning(f"No se pudieron obtener estad√≠sticas de queries: {e}")


async def analyze_unused_indexes(conn: asyncpg.Connection):
    """Identifica √≠ndices que no se est√°n utilizando."""
    print("\n=== √çNDICES NO UTILIZADOS ===\n")
    
    query = """
    SELECT 
        schemaname,
        tablename,
        indexname,
        idx_scan,
        idx_tup_read,
        idx_tup_fetch
    FROM pg_stat_user_indexes
    WHERE schemaname = 'public'
    AND idx_scan = 0
    ORDER BY tablename, indexname;
    """
    
    rows = await conn.fetch(query)
    
    if rows:
        headers = ["Tabla", "√çndice", "Escaneos", "Tuplas Le√≠das", "Tuplas Obtenidas"]
        data = []
        
        for row in rows:
            data.append([
                row['tablename'],
                row['indexname'],
                row['idx_scan'],
                row['idx_tup_read'],
                row['idx_tup_fetch']
            ])
        
        print(tabulate(data, headers=headers, tablefmt="grid"))
        print(f"\nTotal de √≠ndices no utilizados: {len(rows)}")
    else:
        print("‚úÖ Todos los √≠ndices est√°n siendo utilizados.")


async def analyze_table_statistics(conn: asyncpg.Connection):
    """Analiza estad√≠sticas de las tablas principales."""
    print("\n=== ESTAD√çSTICAS DE TABLAS ===\n")
    
    query = """
    SELECT 
        schemaname,
        tablename,
        n_live_tup as live_tuples,
        n_dead_tup as dead_tuples,
        n_mod_since_analyze as mods_since_analyze,
        last_vacuum,
        last_autovacuum,
        last_analyze,
        last_autoanalyze
    FROM pg_stat_user_tables
    WHERE schemaname = 'public'
    ORDER BY n_live_tup DESC;
    """
    
    rows = await conn.fetch(query)
    
    if rows:
        headers = ["Tabla", "Tuplas Vivas", "Tuplas Muertas", "Mods desde Analyze", "√öltimo Vacuum", "√öltimo Analyze"]
        data = []
        
        for row in rows:
            last_vacuum = row['last_vacuum'] or row['last_autovacuum']
            last_analyze = row['last_analyze'] or row['last_autoanalyze']
            
            data.append([
                row['tablename'],
                f"{row['live_tuples']:,}",
                f"{row['dead_tuples']:,}",
                f"{row['mods_since_analyze']:,}",
                last_vacuum.strftime("%Y-%m-%d %H:%M") if last_vacuum else "Nunca",
                last_analyze.strftime("%Y-%m-%d %H:%M") if last_analyze else "Nunca"
            ])
        
        print(tabulate(data, headers=headers, tablefmt="grid"))


async def suggest_missing_indexes(conn: asyncpg.Connection):
    """Sugiere √≠ndices que podr√≠an mejorar el rendimiento."""
    print("\n=== SUGERENCIAS DE √çNDICES ===\n")
    
    # Buscar columnas frecuentemente usadas en WHERE sin √≠ndices
    suggestions = []
    
    # Verificar foreign keys sin √≠ndices
    fk_query = """
    SELECT
        tc.table_name,
        kcu.column_name,
        ccu.table_name AS foreign_table_name,
        ccu.column_name AS foreign_column_name
    FROM information_schema.table_constraints AS tc
    JOIN information_schema.key_column_usage AS kcu
        ON tc.constraint_name = kcu.constraint_name
        AND tc.table_schema = kcu.table_schema
    JOIN information_schema.constraint_column_usage AS ccu
        ON ccu.constraint_name = tc.constraint_name
        AND ccu.table_schema = tc.table_schema
    WHERE tc.constraint_type = 'FOREIGN KEY' 
    AND tc.table_schema = 'public'
    AND NOT EXISTS (
        SELECT 1
        FROM pg_indexes
        WHERE schemaname = 'public'
        AND tablename = tc.table_name
        AND indexdef LIKE '%' || kcu.column_name || '%'
    );
    """
    
    fk_rows = await conn.fetch(fk_query)
    
    if fk_rows:
        print("üìå Foreign Keys sin √≠ndices (pueden causar lentitud en JOINs):")
        for row in fk_rows:
            suggestion = f"CREATE INDEX idx_{row['table_name']}_{row['column_name']} ON public.{row['table_name']}({row['column_name']});"
            suggestions.append(suggestion)
            print(f"  - {row['table_name']}.{row['column_name']} ‚Üí {row['foreign_table_name']}.{row['foreign_column_name']}")
    
    # Sugerir √≠ndices para columnas de fecha com√∫nmente filtradas
    date_columns = [
        ('chat_messages', 'created_at'),
        ('training_sessions', 'session_date'),
        ('nutrition_logs', 'log_date'),
        ('usage_metrics', 'metric_date'),
        ('error_logs', 'created_at'),
    ]
    
    print("\nüìå Columnas de fecha que podr√≠an beneficiarse de √≠ndices parciales:")
    for table, column in date_columns:
        suggestion = f"CREATE INDEX idx_{table}_{column}_recent ON public.{table}({column}) WHERE {column} > (NOW() - INTERVAL '30 days');"
        suggestions.append(suggestion)
        print(f"  - {table}.{column} (√∫ltimos 30 d√≠as)")
    
    if suggestions:
        print("\nüìù Script SQL sugerido:")
        print("-- Copiar y ejecutar en Supabase SQL Editor si es necesario")
        for suggestion in suggestions[:5]:  # Mostrar solo las primeras 5
            print(suggestion)
        if len(suggestions) > 5:
            print(f"-- ... y {len(suggestions) - 5} sugerencias m√°s")


async def main():
    """Funci√≥n principal."""
    print("=== AN√ÅLISIS DE RENDIMIENTO DE QUERIES - GENESIS ===")
    print(f"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    try:
        # Conectar a la base de datos
        print("Conectando a Supabase...")
        conn = await get_database_connection()
        print("‚úÖ Conexi√≥n establecida\n")
        
        # Ejecutar an√°lisis
        await analyze_slow_queries(conn)
        await analyze_unused_indexes(conn)
        await analyze_table_statistics(conn)
        await suggest_missing_indexes(conn)
        
        print("\n=== RECOMENDACIONES GENERALES ===")
        print("1. Ejecutar VACUUM ANALYZE regularmente en tablas grandes")
        print("2. Monitorear el crecimiento de tuplas muertas")
        print("3. Revisar y eliminar √≠ndices no utilizados")
        print("4. Considerar particionamiento para tablas muy grandes")
        print("5. Habilitar pg_stat_statements para mejor an√°lisis")
        
        # Cerrar conexi√≥n
        await conn.close()
        
    except Exception as e:
        logger.error(f"Error en el an√°lisis: {e}")
        print(f"\n‚ùå Error: {e}")
        print("\nNota: Este script requiere conexi√≥n directa a PostgreSQL.")
        print("Verifica que las credenciales de Supabase est√©n configuradas correctamente.")


if __name__ == "__main__":
    asyncio.run(main())